{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7f763c0b6358>\n"
     ]
    }
   ],
   "source": [
    "with open('water_threatment_8x5000.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    print(readCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     1 completed out of    100. Loss:  308.874. Accuracy: 1.000.\n",
      "Epoch     2 completed out of    100. Loss:  246.267. Accuracy: 1.000.\n",
      "Epoch     3 completed out of    100. Loss:  186.485. Accuracy: 1.000.\n",
      "Epoch     4 completed out of    100. Loss:  129.683. Accuracy: 1.000.\n",
      "Epoch     5 completed out of    100. Loss:   75.926. Accuracy: 0.999.\n",
      "Epoch     6 completed out of    100. Loss:   27.456. Accuracy: 0.555.\n",
      "Epoch     7 completed out of    100. Loss:   12.834. Accuracy: 0.635.\n",
      "Epoch     8 completed out of    100. Loss:   16.590. Accuracy: 0.927.\n",
      "Epoch     9 completed out of    100. Loss:   17.948. Accuracy: 0.814.\n",
      "Epoch    10 completed out of    100. Loss:   14.216. Accuracy: 0.723.\n",
      "Epoch    11 completed out of    100. Loss:   14.713. Accuracy: 0.823.\n",
      "Epoch    12 completed out of    100. Loss:   15.654. Accuracy: 0.804.\n",
      "Epoch    13 completed out of    100. Loss:   14.850. Accuracy: 0.781.\n",
      "Epoch    14 completed out of    100. Loss:   14.939. Accuracy: 0.804.\n",
      "Epoch    15 completed out of    100. Loss:   15.282. Accuracy: 0.800.\n",
      "Epoch    16 completed out of    100. Loss:   15.124. Accuracy: 0.794.\n",
      "Epoch    17 completed out of    100. Loss:   15.196. Accuracy: 0.801.\n",
      "Epoch    18 completed out of    100. Loss:   15.332. Accuracy: 0.801.\n",
      "Epoch    19 completed out of    100. Loss:   15.322. Accuracy: 0.799.\n",
      "Epoch    20 completed out of    100. Loss:   15.381. Accuracy: 0.800.\n",
      "Epoch    21 completed out of    100. Loss:   15.442. Accuracy: 0.799.\n",
      "Epoch    22 completed out of    100. Loss:   15.459. Accuracy: 0.798.\n",
      "Epoch    23 completed out of    100. Loss:   15.494. Accuracy: 0.796.\n",
      "Epoch    24 completed out of    100. Loss:   15.515. Accuracy: 0.795.\n",
      "Epoch    25 completed out of    100. Loss:   15.522. Accuracy: 0.796.\n",
      "Epoch    26 completed out of    100. Loss:   15.531. Accuracy: 0.799.\n",
      "Epoch    27 completed out of    100. Loss:   15.530. Accuracy: 0.798.\n",
      "Epoch    28 completed out of    100. Loss:   15.525. Accuracy: 0.800.\n",
      "Epoch    29 completed out of    100. Loss:   15.517. Accuracy: 0.799.\n",
      "Epoch    30 completed out of    100. Loss:   15.507. Accuracy: 0.799.\n",
      "Epoch    31 completed out of    100. Loss:   15.499. Accuracy: 0.796.\n",
      "Epoch    32 completed out of    100. Loss:   15.495. Accuracy: 0.796.\n",
      "Epoch    33 completed out of    100. Loss:   15.493. Accuracy: 0.797.\n",
      "Epoch    34 completed out of    100. Loss:   15.495. Accuracy: 0.797.\n",
      "Epoch    35 completed out of    100. Loss:   15.501. Accuracy: 0.794.\n",
      "Epoch    36 completed out of    100. Loss:   15.504. Accuracy: 0.792.\n",
      "Epoch    37 completed out of    100. Loss:   15.501. Accuracy: 0.789.\n",
      "Epoch    38 completed out of    100. Loss:   15.492. Accuracy: 0.786.\n",
      "Epoch    39 completed out of    100. Loss:   15.477. Accuracy: 0.785.\n",
      "Epoch    40 completed out of    100. Loss:   15.458. Accuracy: 0.782.\n",
      "Epoch    41 completed out of    100. Loss:   15.433. Accuracy: 0.780.\n",
      "Epoch    42 completed out of    100. Loss:   15.403. Accuracy: 0.779.\n",
      "Epoch    43 completed out of    100. Loss:   15.369. Accuracy: 0.779.\n",
      "Epoch    44 completed out of    100. Loss:   15.329. Accuracy: 0.777.\n",
      "Epoch    45 completed out of    100. Loss:   15.285. Accuracy: 0.777.\n",
      "Epoch    46 completed out of    100. Loss:   15.235. Accuracy: 0.775.\n",
      "Epoch    47 completed out of    100. Loss:   15.181. Accuracy: 0.772.\n",
      "Epoch    48 completed out of    100. Loss:   15.121. Accuracy: 0.769.\n",
      "Epoch    49 completed out of    100. Loss:   15.655. Accuracy: 0.797.\n",
      "Epoch    50 completed out of    100. Loss:   20.825. Accuracy: 0.791.\n",
      "Epoch    51 completed out of    100. Loss:   19.187. Accuracy: 0.791.\n",
      "Epoch    52 completed out of    100. Loss:   19.005. Accuracy: 0.810.\n",
      "Epoch    53 completed out of    100. Loss:   15.791. Accuracy: 0.771.\n",
      "Epoch    54 completed out of    100. Loss:   15.827. Accuracy: 0.782.\n",
      "Epoch    55 completed out of    100. Loss:   15.535. Accuracy: 0.776.\n",
      "Epoch    56 completed out of    100. Loss:   15.320. Accuracy: 0.766.\n",
      "Epoch    57 completed out of    100. Loss:   14.424. Accuracy: 0.775.\n",
      "Epoch    58 completed out of    100. Loss:   13.968. Accuracy: 0.770.\n",
      "Epoch    59 completed out of    100. Loss:   14.209. Accuracy: 0.771.\n",
      "Epoch    60 completed out of    100. Loss:   14.316. Accuracy: 0.773.\n",
      "Epoch    61 completed out of    100. Loss:   14.272. Accuracy: 0.776.\n",
      "Epoch    62 completed out of    100. Loss:   14.149. Accuracy: 0.774.\n",
      "Epoch    63 completed out of    100. Loss:   14.025. Accuracy: 0.778.\n",
      "Epoch    64 completed out of    100. Loss:   13.962. Accuracy: 0.776.\n",
      "Epoch    65 completed out of    100. Loss:   13.916. Accuracy: 0.779.\n",
      "Epoch    66 completed out of    100. Loss:   13.847. Accuracy: 0.777.\n",
      "Epoch    67 completed out of    100. Loss:   13.780. Accuracy: 0.776.\n",
      "Epoch    68 completed out of    100. Loss:   13.721. Accuracy: 0.774.\n",
      "Epoch    69 completed out of    100. Loss:   13.673. Accuracy: 0.772.\n",
      "Epoch    70 completed out of    100. Loss:   13.644. Accuracy: 0.773.\n",
      "Epoch    71 completed out of    100. Loss:   13.634. Accuracy: 0.770.\n",
      "Epoch    72 completed out of    100. Loss:   13.629. Accuracy: 0.772.\n",
      "Epoch    73 completed out of    100. Loss:   13.630. Accuracy: 0.769.\n",
      "Epoch    74 completed out of    100. Loss:   13.636. Accuracy: 0.767.\n",
      "Epoch    75 completed out of    100. Loss:   13.662. Accuracy: 0.766.\n",
      "Epoch    76 completed out of    100. Loss:   13.715. Accuracy: 0.765.\n",
      "Epoch    77 completed out of    100. Loss:   13.803. Accuracy: 0.764.\n",
      "Epoch    78 completed out of    100. Loss:   13.932. Accuracy: 0.761.\n",
      "Epoch    79 completed out of    100. Loss:   14.064. Accuracy: 0.760.\n",
      "Epoch    80 completed out of    100. Loss:   14.135. Accuracy: 0.756.\n",
      "Epoch    81 completed out of    100. Loss:   14.168. Accuracy: 0.750.\n",
      "Epoch    82 completed out of    100. Loss:   14.200. Accuracy: 0.746.\n",
      "Epoch    83 completed out of    100. Loss:   14.239. Accuracy: 0.737.\n",
      "Epoch    84 completed out of    100. Loss:   14.285. Accuracy: 0.731.\n",
      "Epoch    85 completed out of    100. Loss:   14.340. Accuracy: 0.721.\n",
      "Epoch    86 completed out of    100. Loss:   14.400. Accuracy: 0.714.\n",
      "Epoch    87 completed out of    100. Loss:   14.466. Accuracy: 0.700.\n",
      "Epoch    88 completed out of    100. Loss:   14.535. Accuracy: 0.691.\n",
      "Epoch    89 completed out of    100. Loss:   14.605. Accuracy: 0.683.\n",
      "Epoch    90 completed out of    100. Loss:   14.673. Accuracy: 0.675.\n",
      "Epoch    91 completed out of    100. Loss:   14.740. Accuracy: 0.665.\n",
      "Epoch    92 completed out of    100. Loss:   14.806. Accuracy: 0.658.\n",
      "Epoch    93 completed out of    100. Loss:   14.871. Accuracy: 0.653.\n",
      "Epoch    94 completed out of    100. Loss:   14.937. Accuracy: 0.646.\n",
      "Epoch    95 completed out of    100. Loss:   15.003. Accuracy: 0.638.\n",
      "Epoch    96 completed out of    100. Loss:   15.068. Accuracy: 0.631.\n",
      "Epoch    97 completed out of    100. Loss:   15.136. Accuracy: 0.627.\n",
      "Epoch    98 completed out of    100. Loss:   15.205. Accuracy: 0.626.\n",
      "Epoch    99 completed out of    100. Loss:   15.275. Accuracy: 0.624.\n",
      "Epoch   100 completed out of    100. Loss:   15.348. Accuracy: 0.623.\n"
     ]
    }
   ],
   "source": [
    "# Для загрузки данных из csv.\n",
    "import csv\n",
    "# Библиотеки машинного обучения.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Библиотека для работы с массивами.\n",
    "import numpy as np\n",
    "# Библиотека для построения графиков.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Зерно для воспроизводимости.\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "# TODO: Почему не работает? Исправить!\n",
    "tf.set_random_seed(random_state)\n",
    "tf.random.set_random_seed(random_state)\n",
    "\n",
    "\n",
    "# Функция создания обучающей и тестовой выборок.\n",
    "def create_feature_sets_and_labels(file, test_size = 0.2):\n",
    "    # Открытие csv-файла.\n",
    "    with open(file) as csvfile:\n",
    "        readCSV = np.genfromtxt(file, delimiter=',')\n",
    "        readCSV = np.delete(readCSV, 0, 0)\n",
    "        \n",
    "        # Строка для отладки.\n",
    "        # print(readCSV)\n",
    "        \n",
    "        np.random.shuffle(readCSV)\n",
    "        \n",
    "        # Строка для отладки.\n",
    "        # print(readCSV)\n",
    "        \n",
    "        # Строки для отладки.\n",
    "        '''\n",
    "        print(len(readCSV))\n",
    "        print(readCSV[0:2,0:2])\n",
    "        for row in readCSV:\n",
    "            print(row)\n",
    "        '''\n",
    "        \n",
    "        # Деление выборки\n",
    "        testing_size = int(test_size*len(readCSV))\n",
    "        train_x = readCSV[:-testing_size,:-1]\n",
    "        train_y = readCSV[:-testing_size,-1:]\n",
    "        test_x = readCSV[-testing_size:,:-1]\n",
    "        test_y = readCSV[-testing_size:,-1:]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "# Создание обучающей и тестовой выборок из csv-файла с исходной выборкой.\n",
    "train_x, train_y, test_x, test_y = create_feature_sets_and_labels('water_threatment_8x5000.csv')\n",
    "\n",
    "# Строки для отладки.\n",
    "'''\n",
    "print()\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print()\n",
    "print(len(train_y))\n",
    "print(train_y)\n",
    "print()\n",
    "print(len(test_x))\n",
    "print(test_x)\n",
    "print()\n",
    "print(len(test_y))\n",
    "print(test_y)\n",
    "'''\n",
    "\n",
    "# Другой способ задания количества нейронов в слое.\n",
    "'''\n",
    "n_neurons = 13\n",
    "n_nodes_hl1 = n_neurons\n",
    "n_nodes_hl2 = n_neurons\n",
    "n_nodes_hl3 = n_neurons\n",
    "'''\n",
    "\n",
    "# Количество нейронов в слоях нейронной сети.\n",
    "n_nodes_hl1 = 11\n",
    "n_nodes_hl2 = 8\n",
    "n_nodes_hl3 = 5\n",
    "\n",
    "# Количество классов - два.\n",
    "n_classes = 2\n",
    "\n",
    "# При обучении нейронная сеть будет получать наблюдения пачками.\n",
    "# Это размер пачки.\n",
    "batch_size = 500\n",
    "\n",
    "# Переменные для обучающей и тестовой выборок,\n",
    "# которые будут инициализированы при обучении нейронной сети.\n",
    "x = tf.placeholder('float',[None, 8])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "\n",
    "# Задание структуры нейронной сети.\n",
    "# TODO: Выяснить почему не работает задание зерна для функций tensorflow.\n",
    "def neural_network_model(data):\n",
    "    # Задание весов нейронов для 3 скрытых слоев и выходного слоя.\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([8, n_nodes_hl1])),\n",
    "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                   'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    # Описание процесса обучения сети с использованием функции активации RELU.\n",
    "    # TODO: Попробовать другие функции обучения после того, как работа нейронной сети\n",
    "    # станет стабильной.\n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    output = tf.matmul(l3, output_layer['weights']) + output_layer['biases']\n",
    "    # Выдача функцией выходных значений.\n",
    "    return output\n",
    "\n",
    "\n",
    "# Функция обучения нейронной сети.\n",
    "def train_neural_network(x):\n",
    "    # Получение прогноза нейронной сетью.\n",
    "    prediction = neural_network_model(x)\n",
    "    # Вычисление функции потерь.\n",
    "    # TODO: 1. Подобрать функцию с перекрестной энтропией, более подходящую для\n",
    "    # бинарной классификации, если такая найдется.\n",
    "    # TODO: 2. Переделать под совместимость со следующим обновлением библиотеки.\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\n",
    "    # Минимизация функции потерь.\n",
    "    # TODO: Посмотреть какие еще есть функции минимизации.\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    # Количество эпох обучения.\n",
    "    # TODO: Вынести из функции обучения сети.\n",
    "    hm_epochs = 100\n",
    "    # Процесс обучения нейронной сети - работает только тогда,\n",
    "    # когда вызывается функция обучения.\n",
    "    with tf.Session() as sess:\n",
    "        # Инициализация переменных.\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        # Процесс обучения производится заданное количество эпох.\n",
    "        for epoch in range(hm_epochs):\n",
    "            # Переменная потерь за эпоху.\n",
    "            epoch_loss = 0\n",
    "            # Цикл обучения по пачкам, на случай очень большого количества данных.\n",
    "            i = 0\n",
    "            while i < len(train_x):\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "                # Пачки наблюдений.\n",
    "                batch_x = np.array(train_x[start:end])\n",
    "                batch_y = np.array(train_y[start:end])\n",
    "                # Расчет и оптимизация функции потерь.\n",
    "                _, c = sess.run([optimizer, loss], feed_dict={x: batch_x,y: batch_y})\n",
    "                # Подсчет потерь.\n",
    "                epoch_loss += c\n",
    "                # Переход к следующей пачке наблюдений.\n",
    "                i += batch_size\n",
    "            \n",
    "            # Вариант подачи выборки на обучение нейронной сети.\n",
    "                '''\n",
    "                for _ in range(int(water_threatment/batch_size)):\n",
    "                    x, y = \n",
    "                '''\n",
    "            \n",
    "            # Количество правильных прогнозов.\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            # Доля правильных прогнозов.\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            # Информация об обучении за эпоху.\n",
    "            print('Epoch {:5.0f}'.format(epoch + 1),\n",
    "                  'completed out of {:6.0f}.'.format(hm_epochs),\n",
    "                  'Loss: {:8.3f}.'.format(epoch_loss),\n",
    "                  'Accuracy: {:1.3f}.'.format(accuracy.eval({x:test_x, y:test_y})))\n",
    "\n",
    "\n",
    "# Обучение нейронной сети.\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
